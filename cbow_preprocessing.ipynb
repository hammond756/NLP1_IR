{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://www.daniweb.com/programming/software-development/code/216839/number-to-word-converter-python\n",
    "def int2word(n):\n",
    "    \"\"\"\n",
    "    convert an integer number n into a string of english words\n",
    "    \"\"\"\n",
    "    \n",
    "    # Return any string that is not all digits\n",
    "    if not all([char.isdigit() for char in n]):\n",
    "        return n\n",
    "    \n",
    "    # break the number into groups of 3 digits using slicing\n",
    "    # each group representing hundred, thousand, million, billion, ...\n",
    "    n3 = []\n",
    "    r1 = \"\"\n",
    "    # create numeric string\n",
    "    ns = str(n)\n",
    "    for k in range(3, 33, 3):\n",
    "        r = ns[-k:]\n",
    "        q = len(ns) - k\n",
    "        # break if end of ns has been reached\n",
    "        if q < -2:\n",
    "            break\n",
    "        else:\n",
    "            if  q >= 0:\n",
    "                n3.append(int(r[:3]))\n",
    "            elif q >= -1:\n",
    "                n3.append(int(r[:2]))\n",
    "            elif q >= -2:\n",
    "                n3.append(int(r[:1]))\n",
    "        r1 = r\n",
    "    \n",
    "    #print n3  # test\n",
    "    \n",
    "    # break each group of 3 digits into\n",
    "    # ones, tens/twenties, hundreds\n",
    "    # and form a string\n",
    "    nw = \"\"\n",
    "    for i, x in enumerate(n3):\n",
    "        b1 = x % 10\n",
    "        b2 = (x % 100)//10\n",
    "        b3 = (x % 1000)//100\n",
    "        #print b1, b2, b3  # test\n",
    "        if x == 0:\n",
    "            continue  # skip\n",
    "        else:\n",
    "            t = thousands[i]\n",
    "        if b2 == 0:\n",
    "            nw = ones[b1] + t + nw\n",
    "        elif b2 == 1:\n",
    "            nw = tens[b1] + t + nw\n",
    "        elif b2 > 1:\n",
    "            nw = twenties[b2] + ones[b1] + t + nw\n",
    "        if b3 > 0:\n",
    "            nw = ones[b3] + \"hundred \" + nw\n",
    "    return nw.strip().split()\n",
    "\n",
    "############# globals ################\n",
    "ones = [\"\", \"one \",\"two \",\"three \",\"four \", \"five \",\n",
    "    \"six \",\"seven \",\"eight \",\"nine \"]\n",
    "tens = [\"ten \",\"eleven \",\"twelve \",\"thirteen \", \"fourteen \",\n",
    "    \"fifteen \",\"sixteen \",\"seventeen \",\"eighteen \",\"nineteen \"]\n",
    "twenties = [\"\",\"\",\"twenty \",\"thirty \",\"forty \",\n",
    "    \"fifty \",\"sixty \",\"seventy \",\"eighty \",\"ninety \"]\n",
    "thousands = [\"\",\"thousand \",\"million \", \"billion \", \"trillion \",\n",
    "    \"quadrillion \", \"quintillion \", \"sextillion \", \"septillion \",\"octillion \",\n",
    "    \"nonillion \", \"decillion \", \"undecillion \", \"duodecillion \", \"tredecillion \",\n",
    "    \"quattuordecillion \", \"quindecillion\", \"sexdecillion \", \"septendecillion \", \n",
    "    \"octodecillion \", \"novemdecillion \", \"vigintillion \"]\n",
    "\n",
    "def digits_to_text(document):\n",
    "    digits_to_text = []\n",
    "    for token in document:\n",
    "        temp = int2word(token)\n",
    "        if type(temp) is list:\n",
    "            digits_to_text.extend(temp)\n",
    "        else:\n",
    "            digits_to_text.append(temp)\n",
    "\n",
    "    return digits_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import pprint\n",
    "from collections import Counter,defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# TODO: find scientific reference that also claims Snowball is better\n",
    "# alternatively: http://www.nltk.org/howto/stem.html claims this already.\n",
    "from nltk.stem import SnowballStemmer, PorterStemmer\n",
    "\n",
    "# check if stopword corpus is available on your system\n",
    "try:\n",
    "    _ = stopwords.words('english')\n",
    "except:\n",
    "    nltk.download('stopwords')\n",
    "    \n",
    "try:\n",
    "    _ = WordNetLemmatizer().lemmatize('test')\n",
    "except:\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "# Embeddings don't work well for words that occur < 5 times\n",
    "THRESHOLD = 5\n",
    "UNK = \"<unk>\"\n",
    "\n",
    "def hide_infrequent_words(document, threshold):\n",
    "    counter = Counter(document)\n",
    "    new_document = []\n",
    "    \n",
    "    for word in document:\n",
    "        if counter[word] > threshold:\n",
    "            new_document.append(word)\n",
    "    \n",
    "    return new_document\n",
    "\n",
    "def filter_document(document):\n",
    "    \"\"\"Filter list of words based on some conventional methods, like removing stopwords and\n",
    "    lemmatization\"\"\"\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = stopwords.words('english')\n",
    "    document = list(filter(lambda x: x not in stop_words, document))\n",
    "\n",
    "    # [I, am, 34] -> [I, am, thirty, four]\n",
    "    document = digits_to_text(document)\n",
    "\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    document = list(map(lemmatizer.lemmatize, document))\n",
    "\n",
    "    return document\n",
    "\n",
    "def make_context_vector(context, w2i):\n",
    "    idxs = [w2i[w] for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return autograd.Variable(tensor)\n",
    "\n",
    "class DialogDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, json_data, image_features, img2feat, transform=None):\n",
    "        \n",
    "        with open(img2feat, 'r') as f:\n",
    "            self.img2feat = json.load(f)['IR_imgid2id']\n",
    "            \n",
    "        self.img_features = np.asarray(h5py.File(image_features, 'r')['img_features'])\n",
    "        self.json_data = pd.read_json(json_data, orient='index')\n",
    "        self.corpus = filter_document(self.get_words())\n",
    "        self.corpus = hide_infrequent_words(self.corpus)\n",
    "        self.vocab = list(set(self.corpus))\n",
    "        \n",
    "        # Add the UNK token to the vocab\n",
    "        self.vocab.append(UNK)\n",
    "        \n",
    "        # Make w2i return idx of UNK by default\n",
    "        self.w2i = {word : i for i, word in enumerate(self.vocab)}\n",
    "        self.w2i = defaultdict(lambda: self.w2i[UNK], self.w2i)\n",
    "        \n",
    "    # collect all the words from dialogs and \n",
    "    # captions and use them to create embedding map\n",
    "    def get_words(self):\n",
    "        words = []\n",
    "        for idx in range(len(self)):\n",
    "            item = self.json_data.iloc[idx]\n",
    "\n",
    "            # Flatten dialog and add caption into 1d array\n",
    "            dialog = [word for line in item.dialog for word in line[0].split()]\n",
    "            dialog.extend(item.caption.split(' '))\n",
    "\n",
    "            words.append(dialog)\n",
    "\n",
    "        return list(chain.from_iterable(words))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.json_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.json_data.iloc[idx]\n",
    "\n",
    "        # Flatten dialog and add caption into 1d array\n",
    "        dialog = [word for line in item.dialog for word in line[0].split()]\n",
    "        dialog.extend(item.caption.split(' '))\n",
    "        dialog = filter_document(dialog)\n",
    "        dialog = make_context_vector(dialog, self.w2i)\n",
    "\n",
    "        img_ids = np.array(item.img_list)\n",
    "        img_features = [self.img_features[idx] for idx in map(lambda x: self.img2feat[str(x)], img_ids)]\n",
    "        img_features = np.array(img_features)\n",
    "        img_features = Variable(torch.FloatTensor(img_features))\n",
    "        \n",
    "        target_idx = item.target\n",
    "        \n",
    "        return {'dialog' : dialog, 'img_features': img_features}, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class CBOW(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "\n",
    "        #out: 1 x emdedding_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.activation_function1 = nn.ReLU()\n",
    "        \n",
    "        #out: 1 x vocab_size\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        self.activation_function2 = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # i believe .view() is useless here because the sum already produces a 1xEMB_DIM vector\n",
    "        embeds = sum(self.embeddings(inputs)).view(1,-1)\n",
    "        out = self.linear1(embeds)\n",
    "        out = self.activation_function1(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.activation_function2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaxEnt(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, text_module, vocab_size, img_size):\n",
    "        super(MaxEnt, self).__init__()\n",
    "\n",
    "        self.text_module = text_module\n",
    "        self.linear = nn.Linear(vocab_size + img_size, 1)\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        dialog = inp['dialog']\n",
    "        all_img_features = inp['img_features']\n",
    "        \n",
    "        text_features = self.text_module(dialog)\n",
    "        text_features = text_features.expand((all_img_features.size(0), text_features.size(1)))\n",
    "    \n",
    "        concat = torch.cat((all_img_features, text_features), 1)\n",
    "        \n",
    "        scores = self.linear(concat)\n",
    "        scores = F.log_softmax(scores.transpose(0, 1))\n",
    "        \n",
    "        return scores\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 4.85 s, total: 1min 14s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_EASY = ['Data', 'sample_easy.json']\n",
    "TRAIN_EASY = ['Data', 'Easy', 'IR_train_easy.json']\n",
    "VALID_EASY = ['Data', 'Easy', 'IR_val_easy.json']\n",
    "IMG_FEATURES = ['Data', 'Features', 'IR_image_features.h5']\n",
    "INDEX_MAP = ['Data', 'Features', 'IR_img_features2id.json']\n",
    "\n",
    "IMG_SIZE = 2048\n",
    "EMBEDDING_DIM = 5\n",
    "\n",
    "torch.manual_seed(1)\n",
    "# dialog_data = DialogDataset(os.path.join(*SAMPLE_EASY), os.path.join(*IMG_FEATURES), os.path.join(*INDEX_MAP))\n",
    "%time dialog_data = DialogDataset(os.path.join(*TRAIN_EASY), os.path.join(*IMG_FEATURES), os.path.join(*INDEX_MAP))\n",
    "valid_data = DialogDataset(os.path.join(*VALID_EASY), os.path.join(*IMG_FEATURES), os.path.join(*INDEX_MAP))\n",
    "\n",
    "vocab_size = len(dialog_data.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 5000\n",
      "Epoch 1: 9.936207246780395\n",
      "0 / 5000\n",
      "Epoch 2: 9.565549840927124\n",
      "0 / 5000\n",
      "Epoch 3: 9.252888078689574\n",
      "0 / 5000\n",
      "Epoch 4: 9.162663965225219\n",
      "0 / 5000\n",
      "Epoch 5: 9.142481765747071\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 4\n",
    "\n",
    "def make_window(words, context_size, batch_size=1):\n",
    "    #Find N words before, and two words after given word.\n",
    "    for i in range(context_size, len(words) - context_size):\n",
    "        for j in range(batch_size):\n",
    "            context = words[i - context_size:i - 1] + words[i + 1:i+context_size]\n",
    "            target = words[i]\n",
    "            yield context, target\n",
    "\n",
    "def learn_embeddings(data):\n",
    "        \n",
    "    model = CBOW(len(data.vocab), EMBEDDING_DIM)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-02)\n",
    "    \n",
    "    for epoch in range(1, 6):\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (context, target) in enumerate(make_window(data.corpus, CONTEXT_SIZE)):\n",
    "            \n",
    "            inp = make_context_vector(context, data.w2i)\n",
    "            target = Variable(torch.LongTensor([data.w2i[target]]))\n",
    "\n",
    "            pred = model(inp)\n",
    "\n",
    "            loss = loss_func(pred, target)\n",
    "            total_loss += loss.data[0]\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if i % 500 == 0:\n",
    "                print('{} / 5000'.format(i))\n",
    "\n",
    "            if i == 100: \n",
    "                break\n",
    "            \n",
    "        print(\"Epoch {}: {}\".format(epoch, total_loss / 100))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = learn_embeddings(dialog_data)\n",
    "# to_path = ['saved_models', 'embeddings', 'cbow_100_embedding_5_epochs_5000_datapoints_1e-02_LR.h5']\n",
    "# torch.save(model.state_dict(), os.path.join(*to_path))\n",
    "\n",
    "giraffe = make_context_vector('giraffe', dialog_data.w2i)\n",
    "zebra = make_context_vector('zebra', dialog_data.w2i)\n",
    "see = make_context_vector('see', dialog_data.w2i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.0000\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = F.log_softmax(model(giraffe))\n",
    "print(torch.sum(torch.exp(pred), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.3798 -2.2154 -2.3290 -2.2380 -2.2970 -2.3537 -2.3421 -2.3183 -2.3748 -2.1973\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_path = ['saved_models', 'embeddings', 'cbow_100_embedding_5_epochs_5000_datapoints_1e-02_LR.h5']\n",
    "cbow_model = model\n",
    "cbow_model.load_state_dict(torch.load(os.path.join(*from_path)))\n",
    "max_ent = MaxEnt(cbow_model, vocab_size, IMG_SIZE)\n",
    "max_ent(dialog_data[0][0])\n",
    "max_ent(valid_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, data, loss_func):\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i, (inp, target) in enumerate(data):\n",
    "        pred = model(inp)\n",
    "        target = Variable(torch.LongTensor(np.array([target])))\n",
    "        \n",
    "        loss = loss_func(pred, target)\n",
    "        total_loss += loss\n",
    "        \n",
    "        if i == 20:\n",
    "            break\n",
    "            \n",
    "    return total_loss / 20\n",
    "\n",
    "def predict(model, data):\n",
    "    correct = 0\n",
    "    \n",
    "    for i, (inp, target) in enumerate(data):\n",
    "        pred = model(inp)\n",
    "        img, idx = torch.max(pred, 1)\n",
    "        if idx.data[0] == target:\n",
    "            correct += 1\n",
    "        \n",
    "        if i == 20:\n",
    "            break\n",
    "    \n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 2.312025718688965\n",
      "2.3952348232269287\n",
      "Epoch 2: 2.299572243690491\n",
      "2.388327121734619\n",
      "Epoch 3: 2.2882035613059997\n",
      "2.381679058074951\n",
      "Epoch 4: 2.277162404060364\n",
      "2.3752832412719727\n",
      "Epoch 5: 2.2664368081092836\n",
      "2.3691282272338867\n",
      "Epoch 6: 2.2560134434700014\n",
      "2.3632020950317383\n",
      "Epoch 7: 2.2458789324760438\n",
      "2.3574938774108887\n",
      "Epoch 8: 2.2360202717781066\n",
      "2.351992130279541\n",
      "Epoch 9: 2.2264252245426177\n",
      "2.3466873168945312\n",
      "Epoch 10: 2.2170820844173433\n",
      "2.3415701389312744\n",
      "[2.3952348232269287, 2.388327121734619, 2.381679058074951, 2.3752832412719727, 2.3691282272338867, 2.3632020950317383, 2.3574938774108887, 2.351992130279541, 2.3466873168945312, 2.3415701389312744]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "cbow_model = CBOW(vocab_size, EMBEDDING_DIM)\n",
    "max_ent = MaxEnt(cbow_model, vocab_size, IMG_SIZE)\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = optim.Adam(max_ent.parameters(), lr=1e-05)\n",
    "\n",
    "validation_errors = []\n",
    "lines_for_csv = []\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    total_loss = 0\n",
    "    for i, (inp, target) in enumerate(dialog_data):\n",
    "        \n",
    "        # Make prediction\n",
    "        pred = max_ent(inp)\n",
    "        target = Variable(torch.LongTensor(np.array([target])))\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_func(pred, target)\n",
    "        total_loss += loss.data[0]\n",
    "        \n",
    "        # Zero out gradients\n",
    "        max_ent.zero_grad()\n",
    "        \n",
    "        # Backpropagate and update parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i == 100:\n",
    "            break\n",
    "        \n",
    "            \n",
    "    total_loss = total_loss / 100\n",
    "    print(\"Epoch {}: {}\".format(epoch, total_loss))\n",
    "    print(\"Correctly predicted {} / 20\".format(predict(max_ent, valid_data)))\n",
    "    \n",
    "    val = validate(max_ent, valid_data, loss_func)\n",
    "    print(val.data[0])\n",
    "    validation_errors.append(val.data[0])\n",
    "    \n",
    "    lines_for_csv.append(\"{},{},{}\\n\".format(epoch, total_loss, val.data[0]))\n",
    "    \n",
    "# with open('cbow_preprocessed_10_epochs_1e-05_embed_100_easy.csv', 'w') as f:\n",
    "#     f.writelines(lines_for_csv)\n",
    "    \n",
    "print(validation_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
